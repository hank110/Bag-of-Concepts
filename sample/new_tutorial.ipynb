{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for BOC (Bag-of-Concepts)\n",
    "\n",
    "- This tutorial is a re-implementation of Kim, Han Kyul, Hyunjoong Kim, and Sungzoon Cho. \"Bag-of-Concepts: Comprehending Document Representation through Clustering Words in Distributed Representation.\" Neurocomputing (2017).\n",
    "\n",
    "- It will show you how to use this package to create sample BOC documents vectors as presented in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the package and designate the location of the input trext file.\n",
    "\n",
    "- Sample text file contains 5,000 articles from Reuter dataset used in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bagofconcepts as bc\n",
    "\n",
    "# pip install bagofconcepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path='./sample_data/sample_articles.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set parameters for training BOC\n",
    "\n",
    "- To train BOC, embedding dimension, context window size, minimum frequency and number of concepts must bedefined as parameters.\n",
    "- **Embedding dimension** denotes the dimensions of word vectors to be trained from word2vec\n",
    "- **Context window size** refers to the number of precedeing and subsequent words that are going to be regarded as contexts for a given input word\n",
    "- Words with frequencies below **minimum frequency** will be ignored in the model\n",
    "- ** The number of concepts** indicates the value of k to be used for spherical clustering. (number of concepts & dimensions of document vectors to be trained)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train BOC document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boc_model=bc.BOCModel(doc_path=document_path, embedding_dim=200, context=8, min_freq=100, num_concept=100 )\n",
    "\n",
    "boc_matrix,word2concept_list,idx2word_converter=boc_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train=boc_matrix[0:4000]\n",
    "X_test=boc_matrix[4000:]\n",
    "Y_train=labels[0:4000]\n",
    "Y_test=labels[4000:]\n",
    "\n",
    "\n",
    "parameters={'C':[0.5, 2], 'kernel':['linear', 'poly']}\n",
    "svr=svm.SVC(kernel=ek,decision_function_shape='ovr')\n",
    "clf1=GridSearchCV(svr, parameters, cv=10)\n",
    "clf1.fit(X_train, Y_train)\n",
    "print(\"----------Cross Validation Result----------\")\n",
    "print(clf1.best_score_)\n",
    "print(clf1.best_params_)\n",
    "\n",
    "\n",
    "print(\"----------Prediction Result----------\")\n",
    "yhat=clf1.predict(X_test)\n",
    "print(f1_score(Y_test, yhat, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Two output files are created\n",
    "\n",
    "- ```w2c_d200_w8_mf50_c100.csv``` contains information about each word's assigned concept\n",
    "- ```boc_d200_w8_mf50_c100.csv``` contains actual BOC document vectors for the input documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using the generated BOC document vectors as inputs, document classifiers can be trained\n",
    "\n",
    "- Using the sample articles and labels, SVM (support vector machine) will be trained to classify each document's category\n",
    "- First 4,000 articles will be used as a training data, while the rest of 1,000 articles will be used as a test data\n",
    "- 10 Fold Cross Validation is applied to search for the optimal SVM model amongst various combinations of parameters (e.g kernel type, regularization terms)\n",
    "- F1 score of prediction from test set will be printed (It will take while!)\n",
    "- Try training different types of document classifiers using BOC vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Cross Validation Result----------\n",
      "0.75075\n",
      "{'kernel': 'linear', 'C': 0.5}\n",
      "----------Prediction Result----------\n",
      "0.758\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "BOC_matrix=genfromtxt('boc_d200_w8_mf50_c100.csv', delimiter=',')\n",
    "\n",
    "with open('./sample_data/sample_labels.txt') as f:\n",
    "    labels=[]\n",
    "    for line in f:\n",
    "        labels.append(line)\n",
    "        \n",
    "X_train=BOC_matrix[0:4000]\n",
    "X_test=BOC_matrix[4000:]\n",
    "Y_train=labels[0:4000]\n",
    "Y_test=labels[4000:]\n",
    "\n",
    "\n",
    "parameters={'C':[0.5, 2], 'kernel':['linear', 'poly']}\n",
    "svr=svm.SVC(kernel=ek,decision_function_shape='ovr')\n",
    "clf1=GridSearchCV(svr, parameters, cv=10)\n",
    "clf1.fit(X_train, Y_train)\n",
    "print(\"----------Cross Validation Result----------\")\n",
    "print(clf1.best_score_)\n",
    "print(clf1.best_params_)\n",
    "\n",
    "\n",
    "print(\"----------Prediction Result----------\")\n",
    "yhat=clf1.predict(X_test)\n",
    "print(f1_score(Y_test, yhat, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
